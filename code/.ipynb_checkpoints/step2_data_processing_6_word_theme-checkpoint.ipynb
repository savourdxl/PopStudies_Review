{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "path = os.path.abspath(os.path.dirname(os.getcwd())) + '\\\\data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\savou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\savou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\savou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\savou\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_article = pd.read_csv(path+'\\\\info\\\\info_article_o_7_m.csv')\n",
    "info_issue = pd.read_csv(path+'\\\\info\\\\info_issue_o_7.csv')\n",
    "info_year = pd.read_csv(path+'\\\\info\\\\info_year_o_7.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def title_to_word(i_article):\n",
    "    \n",
    "    # porter_stemmer = PorterStemmer()\n",
    "    # porter_stemmer.stem('presumably')\n",
    "    # nltk.pos_tag(['institution'])\n",
    "    wordnet_lematizer = WordNetLemmatizer()\n",
    "    \n",
    "    text = info_article.iloc[i_article]['name_book']\n",
    "    \n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    words = [wordnet_lematizer.lemmatize(i_word) for i_word in words]\n",
    "    words = [i_word for i_word in words if i_word not in stopwords.words('english')]\n",
    "    \n",
    "    english_punctuations = [',','.',':',';','?','!','(',')','[','’',\n",
    "                            ']','@','&','#','%','$','{','}','--','-']\n",
    "    words = [i_word for i_word in words if i_word not in english_punctuations]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_article in range(info_article.shape[0]):\n",
    "    \n",
    "    info_article.loc[i_article, 'name_book_words'] = str(title_to_word(i_article))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# info_article.columns.values\n",
    "info_article = info_article[['number_volume', 'number_issue', 'number_article', \n",
    "                             'year', 'period', \n",
    "                             'type_decide', 'type_1', 'type_2', \n",
    "                             'name_book', 'name_book_words', 'name_book_len', 'keyword', \n",
    "                             'author_number', 'author_info',\n",
    "                             'page_start', 'page_end', 'page_quant', \n",
    "                             'date_receive', 'date_accept', 'date_online', \n",
    "                             'views', 'Crossref', 'Web_of_Science']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number_volume</th>\n",
       "      <th>number_issue</th>\n",
       "      <th>number_article</th>\n",
       "      <th>year</th>\n",
       "      <th>period</th>\n",
       "      <th>type_decide</th>\n",
       "      <th>type_1</th>\n",
       "      <th>type_2</th>\n",
       "      <th>name_book</th>\n",
       "      <th>name_book_words</th>\n",
       "      <th>...</th>\n",
       "      <th>author_info</th>\n",
       "      <th>page_start</th>\n",
       "      <th>page_end</th>\n",
       "      <th>page_quant</th>\n",
       "      <th>date_receive</th>\n",
       "      <th>date_accept</th>\n",
       "      <th>date_online</th>\n",
       "      <th>views</th>\n",
       "      <th>Crossref</th>\n",
       "      <th>Web_of_Science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-1</td>\n",
       "      <td>introduction</td>\n",
       "      <td>introduction</td>\n",
       "      <td>Introduction</td>\n",
       "      <td>introduction</td>\n",
       "      <td>['introduction']</td>\n",
       "      <td>...</td>\n",
       "      <td>[('Thomas P. Boje', 'male', \"['Sweden']\", ' De...</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 Oct 2013</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-1</td>\n",
       "      <td>article</td>\n",
       "      <td>Article</td>\n",
       "      <td>Original Articles</td>\n",
       "      <td>national models for making and legitimating el...</td>\n",
       "      <td>['national', 'model', 'making', 'legitimating'...</td>\n",
       "      <td>...</td>\n",
       "      <td>[('Michel Bauer', 'male', \"['France']\", ' Obse...</td>\n",
       "      <td>9</td>\n",
       "      <td>31</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 Oct 2013</td>\n",
       "      <td>78</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-1</td>\n",
       "      <td>article</td>\n",
       "      <td>Article</td>\n",
       "      <td>Original Articles</td>\n",
       "      <td>models of the family, women’s role and social ...</td>\n",
       "      <td>['model', 'family', 'woman', 'role', 'social',...</td>\n",
       "      <td>...</td>\n",
       "      <td>[('Catherine Hakim', 'female', \"['United Kingd...</td>\n",
       "      <td>33</td>\n",
       "      <td>58</td>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 Oct 2013</td>\n",
       "      <td>441</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-1</td>\n",
       "      <td>article</td>\n",
       "      <td>Article</td>\n",
       "      <td>Original Articles</td>\n",
       "      <td>the european union and equal opportunities pol...</td>\n",
       "      <td>['european', 'union', 'equal', 'opportunity', ...</td>\n",
       "      <td>...</td>\n",
       "      <td>[('Sylvia Walby', 'female', \"['United Kingdom'...</td>\n",
       "      <td>59</td>\n",
       "      <td>80</td>\n",
       "      <td>22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 Oct 2013</td>\n",
       "      <td>142</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1999</td>\n",
       "      <td>1999-1</td>\n",
       "      <td>article</td>\n",
       "      <td>Article</td>\n",
       "      <td>Original Articles</td>\n",
       "      <td>private and public transfers between generatio...</td>\n",
       "      <td>['private', 'public', 'transfer', 'generation'...</td>\n",
       "      <td>...</td>\n",
       "      <td>[('Martin Kohli', 'male', \"['Germany']\", ' Fre...</td>\n",
       "      <td>81</td>\n",
       "      <td>104</td>\n",
       "      <td>24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21 Oct 2013</td>\n",
       "      <td>371</td>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   number_volume number_issue  number_article  year  period   type_decide  \\\n",
       "0              1            1               1  1999  1999-1  introduction   \n",
       "1              1            1               2  1999  1999-1       article   \n",
       "2              1            1               3  1999  1999-1       article   \n",
       "3              1            1               4  1999  1999-1       article   \n",
       "4              1            1               5  1999  1999-1       article   \n",
       "\n",
       "         type_1             type_2  \\\n",
       "0  introduction       Introduction   \n",
       "1       Article  Original Articles   \n",
       "2       Article  Original Articles   \n",
       "3       Article  Original Articles   \n",
       "4       Article  Original Articles   \n",
       "\n",
       "                                           name_book  \\\n",
       "0                                       introduction   \n",
       "1  national models for making and legitimating el...   \n",
       "2  models of the family, women’s role and social ...   \n",
       "3  the european union and equal opportunities pol...   \n",
       "4  private and public transfers between generatio...   \n",
       "\n",
       "                                     name_book_words  ...  \\\n",
       "0                                   ['introduction']  ...   \n",
       "1  ['national', 'model', 'making', 'legitimating'...  ...   \n",
       "2  ['model', 'family', 'woman', 'role', 'social',...  ...   \n",
       "3  ['european', 'union', 'equal', 'opportunity', ...  ...   \n",
       "4  ['private', 'public', 'transfer', 'generation'...  ...   \n",
       "\n",
       "                                         author_info page_start  page_end  \\\n",
       "0  [('Thomas P. Boje', 'male', \"['Sweden']\", ' De...          1         7   \n",
       "1  [('Michel Bauer', 'male', \"['France']\", ' Obse...          9        31   \n",
       "2  [('Catherine Hakim', 'female', \"['United Kingd...         33        58   \n",
       "3  [('Sylvia Walby', 'female', \"['United Kingdom'...         59        80   \n",
       "4  [('Martin Kohli', 'male', \"['Germany']\", ' Fre...         81       104   \n",
       "\n",
       "  page_quant date_receive date_accept  date_online views Crossref  \\\n",
       "0          7          NaN         NaN  21 Oct 2013    26        1   \n",
       "1         23          NaN         NaN  21 Oct 2013    78       14   \n",
       "2         26          NaN         NaN  21 Oct 2013   441       15   \n",
       "3         22          NaN         NaN  21 Oct 2013   142       13   \n",
       "4         24          NaN         NaN  21 Oct 2013   371      194   \n",
       "\n",
       "  Web_of_Science  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_article.to_csv(path+'\\\\info\\\\info_article_o_8.csv',index=False,sep=',')\n",
    "info_article.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defaultdict\n",
    "# from collections import defaultdict\n",
    "\n",
    "### example 1:\n",
    "\n",
    "# dict = {}\n",
    "# dict['age']=10\n",
    "# dict\n",
    "# dict['age']\n",
    "# dict['name']\n",
    "\n",
    "### example 2:\n",
    "\n",
    "# dict = defaultdict(int)\n",
    "# dict[2]='two'\n",
    "# dict[4]\n",
    "# dict['my']\n",
    "# dict['2']\n",
    "\n",
    "### example 3:\n",
    "\n",
    "# dict = defaultdict(str)\n",
    "# dict[3]\n",
    "# dict[3]='I am'\n",
    "# dict['3']='You are'\n",
    "# dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def co_occurrence(words, window_size):\n",
    "    \n",
    "    word_set = set()\n",
    "    \n",
    "    for i_word in words:\n",
    "        \n",
    "        word_set.add(words)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'not,', 'drunk']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
